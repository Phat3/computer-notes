DATABASE 2

------------------------- TRANSACTIONAL SYSTEMS -------------------------


ACID: - Atomicità: la transazione è considerata come una trasformazione autonoma: possibili svolgimenti: - COMMIT: la transazione ha successo
																										 - UNDO: la transazione fa un rollback
																										 - REDO: la transizione fallisce dopo il commit e si avanza allo stato successivo
	  				garantita da: - abort, rollback ecc
	  							  - commit protocol
	  							  - reliability control
	  				
	  - Consistenza: la transazione deve rispettare i vincoli di integrità
	  				 - garantita da: - controllo di integrità sulle query a compile time
	  
	  - Isolamento: la transazione non deve venire influenzata dal comportamento delle altre
	  				garantita da: - controllo di concorrenza
	  
	  - Durabilità: l'effetto della transazione deve essere immagazzinato in modo permanente 
	  				garantito da:  - reliability control
	  				

------------------------- CONCURRENCY CONTROL -------------------------

problemi comuni: - lost update: leggo un dato vecchio, una transazione prima di me aggiorna il dato e io lo sovrascrivo con uno sbagliato ( perdo l'aggiornamento precedente!! )
				 
				 - dirty read: leggo un dato di una transazione che in seguito farà un rollback, il dato letto è quindi sbagliato
				 
				 - non repeatable read: leggo 2 volte lo stesso dato senza aggiornarlo tra le 2 letture, i dat potrebbero essere diversi perchè aggiornati da un'altra transazione
				 
				 - ghost update: se devo eggere più di un dato è possibie che tra la lettura del primo  quello dell'ultimo i dati in mezzo siano stati modificati da altre transazioni
				 
schedule: sequenze di operazioni input output di transazioni concorrenti

scheduler: componente che analiza gli schedule e decide se accettarli o meno
		   deve rifiutare quelli che causano anomalie
		   
serializable schedule: produce lo stesso effetto di uno schedule seriale sulle stesse transazioni

tipi di schedule: - seriale: tutte le operazioni della stessa transazione sono svolte in modo contiguo
				
				  - view serializable(VSR): 2 schedule sono VSR se hanno: - stesse read from: non devo leggere il dato da 2 scritture diverse
				  														  - stesse final write: l'ultima scrittura deve essere sulla stessa risorsa
				  														  
				  - conflict serializable(CSR): 2 transazioni sono in conflitto se operano sullo stesso dato e almeno un operazione è una write
				  								CSR -> VSR
				  								testo la proprietà CSR attraverso un grafo: se è aciclico allora è CSR
				  								
				 - 2PL: nella pratica si usa un sistema di LOCK/UNLOCK sulle risorse: - read: faccio una shared lock
				  																	  - write: faccio una exclusive lock
				  																							  
				  		si usa il metodo two phase locking(2PL) per garantire l'assenza di conflitti: - una risorsa non può più acquisire lock sulle risorse dopo che ha effettuato un unlock
				  																					  - i lock possono essere rilasciati solo dopo un commit o un abort(strict 2PL)
				  																					  
				 - mono timestamp(MonoTS): ogni transazione ha un timestamp che identifica l'istante di inizio(problema: non ho un timestamp globale, devo ricavarlo tramite messaggi)
				 						   
				 						   funzionamento: - lo schedule ha 2 contatori per ogni risorsa: WTM(x) e RTM(x)
				 						   
				 						   				  - lo schedule riceve le richieste con il read TS e il write TS delle transazioni
				 						   				  		
				 						   				  		- read(x, ts): - se ts < WTM(x) l'operazione è rifiutata e l transazione killata(sto cercando di legere un dato vecchio)
				 						   				  					   - altrimenti l'operazione è accettata e RTM(x) = max (RTM(x), ts)
				 						   				  		
				 						   				  		- write(x, ts): - se ts < WTM(x) o ts < RTM(x) l'operazione è annullata e la transazione killata( sto cercando di sovrascrivere un dato che altri hanno già letto con un vecchio)
				 						   				  						- altrimenti la richiesta è accettata e WTM(x) = ts
				 						   				  						
				 						   	è incomparabile con il 2PL ma è sottoinsieme di CSR
				 						   	
				 - multiversion concurrency control(MultiTS): le scritture generano nuove copie e le letture accedono alla copia giusta
				 											  ci sono molti WTM(x) ma un solo RTM(x)
				 											  
				 											  funzionamento: - read(x, ts): sempre accettata, accedo alla copia giusta secondo il mio ts, se ts è maggiore dell'ultima copia di WTM(x) accedo all'ultimo WTM(x)
				 											  					
				 											  				 - write(x, ts): - se ts< RTM(x) la transazione è killata
				 											  				 				 - altrimenti una nuova copia è creata con WTMk(x) = ts 
				 											  				 				  

esistono 4 livelli di isolamento in SQL: - read uncommitted: non ci sono le read lock, permette il dirty read
										
										 - read committed: ci sono le lock ma non è 2PL, posso avere non repeatable read
										 
										 - repeatable read: 2PL, perette i phantom insert
										 
										 - serializable: 2PL con predicate lock, evita tutte le anomalie
										 
sistema di lock gerarchico: sistema di lock con diversa granularità(tabelle, pagine, tuple ecc..)
							
							5 stati di lock: - ISL: intention of share lock: lo faccio sulla pagina che contiene la risorsa se ho intenzione di LEGGERE
											 - IXL: intention of exlusive lock:	lo faccio sulla oagina che contiene la risorsa se ho intenzione di SCRIVERE
											 - SIXL: blocco in shared mode con intenzione di bloccare in exlusive mode in seguito	
											 
deadlock: metodi per evitarlo: - timeout: la transazione è killata dopo un tot di tempo di attesa.
										  problemi: - timeout troppo lungo: perdo tempo inutile
										  			- timeout troppo corto: rischio di killare transazioni che non erano in deadlock
										  			
							   - deadlock prevention: killo transazioni che POTREBBERO andare inn deadlock
							   						  es: assegno ad ogni transazione un "età" e se una transazione aspetta una transazione più giovane la killo
							   						  
							   						  	  posso	avere molte kill inutili es: T1 aspetta T2 che aspetta T3 -> no deadlock ma T1 e T2	killate comunque
							   						  	  
							   - deadlock detection: richiede un algoritmo in grado di capire se le transazioni sono in uno stato di deadlock
							   
							   						 obermark's algorithm: trasmetto le sequenza possibile di deadlock ad un altro nodo se E - Ti - Tj -E con i>j
							   						 						
							   						 					   se in un nodo trovo un ciclo allora sono in deadlock
							   						 					    
							   						  	  																								      
				  								 
				  

------------------------- COMMIT PROTOCOLS -------------------------

ACID distribuito: - Atomicità: proprietà più difficile da ottenere in un sistema distribuito (garantita dai vari protocolli di commit)
				  - Consistenza: se le transazioni preservano la loro integrità sono consistenti, per fare ciò si adotta il 2PL
				  - Isolamento: se tutte le transazioni sono adottano il protocollo "two phase" è garantito
				  - Durabilità: se tutte i branch distribuiti mantengono bene i log è garantita la durabilità
				  
possibili situazioni di errore: - perdita del messaggio
								- problemi ad un nodo (locale)
								- problemi al network
								
protocolli: - Two phase commit: - 2 componenti fondamentali: - transaction manager: coordina i vari componenti in gioco
																					
																					compiti: - prepare: identificare i r. m.
																							 - global commit/abort: prendere decisioni globali sull'esito delle transazioni
																							 - complete: chiudere il protocollo
															
															 - resource manager: nodi local coordinati dal t.m.
															 					
															 					 compiti: - ready: stato che mi identifica agli occhi del t.m (ok se dico si ad una richiesta di prepare)
															 					 		  - local commit/abort: decisione locale sull'esito della transazione
															 					 		  
								funzionamento: - fase 1 : 1 - il t.m scrive sul log "prepare"
														  2 - il t.m manda un messaggio di prepare a tutti gli r.m
														  3 - gli r.m decidono se accettare o no la richiesta di prepare
														  4 - i r.m comunicano la loro decisione al t.m
														  
														  
												- fase 2: 5 - il t.m guarda tutti i messaggi di risposta e se almeno uno è no scrive "global abort" sul log(anche se scade il timeout)
														  	  altrimenti scrive "global commit"
														  6	-  il t.m comunica la decisione a tutti gli r.m
														  7 - gli r.m decidono localmente se accettare o no il commit della transazione
														  8 - gli r.m comunicano con ack al t.m la ricezione del messaggio
														  9 - il t.m scrive "complete" sul log
														  
								problemi: - problemi al t.m : 2 compiti per recuperarlo: - l'ultimo record sul log è "prepare", il fallimento potrebbe aver lasciato dei r.m in stato di blocco 
																						   e si può procedere in 2 modi:
																						   1 - scrivere global abort e portare a termine la fase 2 del protocollo.
																						   2 - ripetere la prima fase
																						   
																						 - l'ultimo record è una global decision, alcuni r.m sono bloccati ripetere la fase 2 del protocollo
																						 
										  - problemi agli r.m : causati da un warm restart: - ultimo record è una local decision: - se commit fare il redo di tutte le azioni dopo
										  																						  - se abort fare l'undo di tutte le azioni
										  													- ultimo record è ready: richiedere l'esito al t.m(remote recovery)
										  													
										  - problemi di network : - perdo messaggi prepare o ready: scade il time out e scrivo global abort
										  						  - perdo messaggi di ack o msg. scade il timeout e ripeto la fase 2 del protocollo
										  						  							   
								ottimizzazioni: - presumed abort protocol: se il t.m riceve un richiesta di remote recovery e non sa ancora in che stato è la transazioe, allora risponde con un global abort
												
												- read-only	optimization: se un r.m vuole solo leggere comunicherà al t.m al posto di "ready" read only e questo r.m  verrà ignorato nella fase 2 del protocollo dal t.m			
												
			- four phase commit: come il two fase cmmit solo che è presente un backup del t.m, ogni volta che il t.m scrive un record sul log lo comunica al backup che a sua volta lo scriverà nel suo log
								 quando si ha un caso di failure nel t.m il backup prenderà il suo posto e diventerà lui il t.m rendendo il failure trasparente.
								 come prima operazione il nuovo t.m creerà un nuovo backup
																	 
			- three phase commit: ogni r.m può essere eletto a t.m: - se come ultimo record ha "ready" allora può ipotizzare che la transazione sia fallita e scrivere global abort
																	- se come ultimo record ha pre- commit può fare un global commit
																										
			- paxos: combina un protocollo con il commit protocol, alcun r.m agiscono da acceptors
										  
			- x-openDTP: espone delle interfacce: - t.m interface: definisce le funzioni del t.m che possono essere chiamate dai client: - tm_init, tm_end: inizia e termina il dialogo con il client
																																		 - t_mopen, tm_term: apre e chiude la sessione con il tm
																																		 - tm_begin: inizia una transazione
																																		 - tm_abort, tm_commit: richiesta di global commit/abort
												  
												  - xa interface: definisce le funzioni dei client remoti	
												  
						  i client sono passivi e il protocollo supporta decisioni euristiche(dopo un failure posso decidere se fare un commit o un abort).
						  usa il protocollo two phase commit con ottimizzazioni		
						  
						  



		
						  
------------------------- DISTRIBUTED DATABASE -------------------------

architetture client server: - client: formula le query e mostra i risultati
							- server: risolve le query e calcola i risultati
							
process nel server: - richieste accodate in una coda di input
					- richieste smistate tra i vari servizi
					- risultato accodato in una coda di output
					- risultato spedito al client appropriato
					
famiglie DBMS: - omogenei: stessa "marca" (oracle, sybase, ecc...)
			   - eterogenei: "marche diverse"
			   
data fragmentation: - proprietà che deve rispettare: - completezza: ogni elemento della tabella T deve essere presente in uno dei suoi frammenti
												     - restorability: la tabella T deve poter essere ricostruita dai suo frammenti
												   
					- tipi di frammentazione: - horizontal fragmentation: - frammento: insieme di tuple
																		  - completezza: disponibilità di tutte le tuple
																		  - restorability: UNIONE di tutte le tuple
											
											  - vertical fragmentation: - frammento: insieme di attributi
																	    - completezza: disponibilità di tutti gli attributi
																	    - restorability: JOIN  sugli attributi
																	  
																	    (PROBLEMA: devo duplicare la chiave primaria su ogni frammento per poter ricostruire)

					- tipi di allocazione: - fully centralized: tutte le tabelle accorpate in un unico db
										   
										   - centralized and distributed (fully replicated): le tabelle risiedono tutte su un unico db ma hanno anche dei doppioni distribuiti su vari altri sistemi
										   
										   - partially distributed, no replication: alcune tabelle sono su un db altre su altri, non ci sono mai dei doppioni
										   
										   - partially centralized and fully distributed: alcune tabelle risiedono su un db centrale mentre nei sotto sistemi risiedono una tabella per OGNI tipo (non posso avere un sotto sistema che non abbia 
										   																																						   un tipo di tabella)
										  
										   - asymmetric allocation: non tutti i sotto sistemi hanno frammenti del sistema centrale
										   
										   - fully distributed, little replication: solo le tuple che hanno un attributo con lo stesso valore sono replicate su più sotto sistemi( es: utente che ha più di un account)
										   
partizionare bene un database: bisogna garantire la TRASPARENZA: 3 livelli: - trasparenza di frammentazione: l'utente vede il db come non frammentato ma unico									
																											 (es: SELECT balance FROM Account WHERE id=1)
																											 
																			- trasparenza di allocazione: l'utente sa che è frammentato ma non ha bisogno di gestire dove sono allocate le risorse, non devo specificare su che macchina
																										  si trovano i frammenti, per lui sono tutti sulla stessa macchina
																										  
																			- trasparenza di linguaggio: l'utente sa che sono frammentate e allocate e lo deve indicare nella query, deve indicare la macchina fisica tramite la "@"s
																			
classificazione applicazioni distribuite SQL: - remote request: permette le sole operazioni di lettura su un unico db
											  - remote transaction: permette l'update su un singolo db
											  - distributed transaction: permette l'update su più db, tutte le query vengono gestite da un singolo db
											  - distributed request: permette l'update e le query vengono gestite da più db

sistemi legacy: basati su vecchi mainframe: - poco documentati
											- obsoleti
											- garantiscono sicurezza 
							
																												





																					
------------------------- PARALLELS AND REPLICATED DB -------------------------		

il parallelismo è garantito dal numero di processori > 1 presenti nel server, possono avere 3 tipi di architetture: - shared nothing: ogni processore ha il suo disco e la sua memoria
																													- shared disk: condividono i vari dischi tra tutti i processori
																													- shared memory: oltre ai dischi condividono anche la memoria centrale

tipi di operazioni: - transactional: operazioni SQL semplici, evase in pochi secondi, il benchmark è misurato in transazioni per secondo
					- data analysis: operazioni complesse, tempo variabile


tipi di parallelismo: - inter-query: tutte le query transazionali vengono svolte su un unico processore
					  - intra-query: le query di data-analysis vengono svolte su più processori contemporaneamente
					  
il costo per transazione aumenta all'aumentare del numero di processori, mentre aumenta il numero di transazioni per secondo

data replication: motivazioni: - ho più probabilità di trovare il dato che cerco se ho più copie( es: se un sistema ha problemi posso prendere il dato da un altro)
 							   - aumenta l'efficienza
 							   
 				  metodi di replicazione: - asymmetric replicaion: se ho un nuovo dato scritto sul sistema è il sistema stesso che si occupa di copiarlo anche sugli altri suoi sistemi copia ( l'update che fa il sistema è considerato una transazione a se)
 				  						  - symmetric replication: quando faccio l'update lo faccio anche su tutti i sistemi copia (tutti gli update sono considerati un unica transazione)
 				  						  
 				  metodi di allineamento: - whole copy: copio tutto il database sui sistemi copia
 				  						  - delta-plus/delta-minus(sono tabelle riempite tramite trigger): aggiungo/rimuovo solo le cose che cambiano
 				  						  
 				  						  
 				  						  


------------------------- DATA WAREHOUSE -------------------------	

data warehouse: descrizione di tutto l'insieme di dati che servono per ricavare una statistica

OLAP: servizi che effettuano analisi suldata warehouse

data mart: sotto-insieme dei data warehouse dove incorporo solo i dati relativi ad una specifica area di business, condividono dati in comune tra i vari data mart

multi-dimensional representation: modello concettuale che descrive l'integrazione tra i vari componenti del data mart.
								  
								  è composto da 3 componenti fondamentali: - fact: componenti fondamentali del data mart (VENDITE ECC..)
								  										   - measures: sono gli attributi del fatto
								  										   - dimension: sono componenti che associati al fatto danno una tabella su cui creare una statistica( es: Prodotto(dimension) - VENDITE(fact), NEGOZIO(dimension) - VENDITE(fact) )
								  
								  è molto utile questo modello perchè è già pronto per essere plamsmato su un db relazionale
								  
								  ogni fatto ha come attributi, oltre alle measures, tutte le chiavi primarie dei dimension a lui collegati
								  
operazioni possibili su data warehouse: - roll up: aggregare tutte le informazioni di un unico valore (es: somma del prodotto vino venduto in un mese)
										- drill down: ricavare il dettaglio di un valore( es: vendita giornaliera del prodotto vino)
										- slice and dice
										- pivot: cambiare angolazione del data cube
										
classificazione OLAP: - ROLAP: basati su db relazionali, possono contenere grandi quantità di dati
					  - MOLAP: ba\sati su db NON relazionali, hanno performance migliori 
					  
					  ottimizzazioni: - bitmap indexes: utili dove ci sono molte operazioni di AND e OR per confrontare predicati
					  				  - join indexes: pre-computano le join tra le tabelle cosi da renderle più efficienti
					  				  - materialized views: pre-computano view utili
					  				  
data mining: processo che permette di ricavare informazioni "nascoste" mettendo insieme più dati tra loro per ricavare una statistica
			
			 si basa sul ragionamento fondamentale body -> head (es: se una persona compra degli sci -> che probabilmente comprerà degli scarponi da sci anche)
			 
			 parametri: - support: probabilità che nella stessa transazione ci sia sia l'head che il body
			 
			 			- confidence: probabilità che ci sia l'head nella transazione t sapendo che c'è il body
			 			



------------------------- PHYSICAL DATA STRUCTURES AND QUERY OPTIMIZATION -------------------------
			 
i DBMS gestiscono i blocchi della memoria secondaria come se fossero un grande spazio unico.
per ogni file storano una tabella ma può anche capitare che un file contenga più tabelle o che una tabella sia splittata su più files

componenti fondamentali: - blocks: componente fisico, la sua grandezza dipende dal file system usato
						 - records: componente logico: la sua grandezza dipende dall'esigenza dell'applicazione
						 
						 se Sr(size record)< Sb(size block) allora posso avere più record all'interno di uno stesso blocco. lo spazio rimanente nel blocco può essere usato(spanned records) oppure no(unspanned recors)
						 
						 
ogni DBMS ha la sua struttura fisica di accesso e i suoi metodi di accesso, i quali sono componenti software che manipolano questa struttura.
la struttura può essere di 3 tipi: - sequential: le tuple vengono immagazzinate in maniera sequenziale sul disco
												 
												 3 tipi diversi: - entry-sequenced: le tuple vengono scritte nell'ordine in cui arrivano; la prima che arriva viene scritta prima
												 									ottima per le operazioni di scrittura e lettura sequenziali
												 									non ottima per la ricerca
												 									
												 				 - array: le tuple possono essere inserite come in u array a second dell'indice; è possibile solo se tutte le tuple hanno la stessa grandezza fissata a priori
												 				 
												 				 - sequentially ordered: le tuple sono ordinate tramite un campo chiamato row key; non si usa quasi più questa tecnica perchè molto poco efficiente quando si ha un inserimento
												 				 
								   - hash based: si basa sul riconoscimento della tupla tramite la coppia chiave valore.
								   				 
								   				 data una struttura di B blocchi, una volta usata la funzione di hash sulla chiave questa restituisce un valore compreso tra 0 e B-1 che è la posizione
								   				  
								   				 2 fasi: - folding: la chiave viene trasformata in un valore intero non negativo
								   				  		 - hashing: la chiave trasformata viene hashata e il valore di ritorno è la posizione della tupla cercata
								   				  		 
								   				  partizionare bene il numero di blocchi: - T: numero di tuple aspettate nella pagina
								   				  										  - F: numero medio di tule presenti in ogni pagina
								   				  										  - B = T/(0.8*F)
								   				  										  
								   				  possono verificarsi collisioni(2 chiavi diverse restituiscono la stessa posizione).
								   				  a questo problema si può ovviare con: - chaining: creo una lista di valori in un unica casella(aggiungo un costo computazionale di O(n) alla ricerca
								   				  										- uso il prossimo blocco in sequenza libero per immagazzinare il valore
								   				  										- uso un file extra chiamato "overflow file" e immagazzino li il dato
								   				  										
								   				  questa struttura è inefficiente sulle ricerche dove non si conosce la chiave o sulle ricerche basate su offset dalla partenza
								   				  	
								
								   - tree based: struttura più usata
								   				
								   				 si avvale di indici( assimilabili all'indice di un libro), possono essere di diversi tipi: - primary index: indice basato sulle chiavi primarie delle tuple
								   				 																							- secondary index: indice basato sugli attributi della tupla
								   				 																							- dense index: per ogni tupla ho un entry nell'index file
								   				 																							- sparse index: ho un entry nell'index file solo ogni tot di tuple
								   				 																							- clustered index: gli indici sono dati dal posizionamento del file nel file system
								   				 																				
								   				 ogni node dell'albero corrisponde a un blocco
								   				 
								   				 2 tipi di albero: - B+ trees: le foglie sono legate tra di loro come una lista, molto efficienti per le interval queries
								   				 				   - B trees: i nodi intermedi hanno 2 puntatori per ogni coppia chiave valore: - uno punta al nodo con la chiave esatta
								   				 				   																				- l'altro punta ad un sotto-albero contenente tutte le chiavi > Ki e < di Ki+1 
								   				 				   																				
								   				 				   	operazioni fondamentali: - SPLIT: se non posso aggiungere una entry in un nodo perchè è pieno allora devo splittare il nodo in 2 e aggiungere il puntatore al nodo padre. cosi mantengo
								   				 				   									  la proprietà che una coppia chiave valore deve puntare sempre a valori di chiave > di K
								   				 				   									  
								   				 				   									  es: nodo padre: 		|| k1 || k6 || || |				inserisco k3					|| k1 || k3 || k6 || |
								   				 				   									  														------------->      
								   				 				   									  	  nodo figlio:		|| k1 || k2 || k4 || k5 |										|| k1 || k2 || || |		|| k3 || k4 || k5 || |
								   				 				   									  	  
								   				 				   							 - MERGE: si ha quando c'e un eliminazione di una chiave e posso unire 2 nodi in uno unico perchè ho tanti posti disponibili quanti sono i valori nel
								   				 				   							 		  blocco da unire
								   				 				   							 		  
								   				 				   							 		  es: nodo padre: 		|| k1 || k3 || k6 || |							 	 elimino k2						|| k1 || k6 ||  || |
								   				 				   									  																			------------->      
								   				 				   									  	  nodo figlio:		|| k1 || k2 || || |		|| k3 || k4 || k5 || |										|| k1 || k3 || k4 || k5 |	
								   				 
								   
nelle strutture sequenziali ed hash based la struttura delle pagine è la stessa ed è la seguente: - block header: contiene le informazioni utili al file system						<------ inizio pagina
																								  
																								  - page header: contiene le informazioni utili al metodo di accesso
																								  
																								  - page dictionary: contiene i puntatori alle varie tuple
																								  
																								  - useful data: contiene le tuple vere e proprie
																								  
																								  - checksum:serve per verificare l'integrità dei dati
																								  
																								  - page trailer: contiene le informazioni utili al metodo di accesso
																								  
																								  - block trailer: contiene le informazioni utili al file system					<------ fine pagina
																								  
																								  
------------------------- XQUERY/XPATH -------------------------																	

xPath sintassi: - 'nodename' : seleziona tutti i figli del nodo specificato

				- '/' : seleziona dal nodo root tutti i nodo
				
				- '//' : seleziona tutti i nodi partendo dal nodo corrente che matchano la ricerca, anche se non sono figli del nodo
				
				- '.' : seleziona il nodo corrente
				
				- '..' : seleziona il padre del nodo corrente
				
				- '@' : seleziona gli attributi
				
				- 'doc(nomeDocumento.xml)' : specifica il documento da aprire
				
				- 'doc(nomeDocumento.xml)/figlio1/figlio2[elemento = "condizione"]/figlio3': specifica da che discendenza partire e che condizioni devono rispettare alcuni figli
				
				- 'doc(nomeDocumento.xml)/figlio1[n] : ritorna l'ennesima occorrenza del figlio1
				
				
				esempi di sintassi abbreviata: - $x/figlio1 : seleziona tutti i discendenti del tipo figlio 1
												
											   - $x//figlio1 : seleziona tutti i nodi di tipo figlio1 indipendentemente da dove sono basta che siano discendenti dei nodi di tipo $x
											   
											   - $x/.. : seleziona il nodo padre
											   
											   - $x/@year :seleziona tutti i nodi che hanno attributo year
											   
											   - $x/. : seleziono me stesso
											   
				predicati: $x/figlio1[predicato] : es: - $x/figlio1[last()] : ultimi figlio di tipo figlio1 e discendenti di $x
														
													   - //title[@lang = 'ita'] : seleziona tutti i nomi che hanno come attributo lang e che sia uguale a 'ita'
													   
													   - /bookstore/book[price] : seleziona tutti i nodi book figli di bookstore e che hanno ome elemento price
													   
				operatore '|' : es: - /bookstore/book/title | //price : seleziona tutti i i title figli di book figli di bookstore E seleziona tutti i prezzi in tutto il documento
				
									- //title | //price : seleziona tutti i titoli presenti nel documento E tutti i prezzi presenti nel documento
									


xQuery: elementi fondamentali : - items : nodi o valori atomici
								
								- nodi: documento | elemento | namespace | attributo | testo ecc..
										   
								- valori atomici : istanza di un valore atomico in XML (decimal,stringa , boolean ecc... )
								
								
		regole di risoluzione delle query: sintassi :(item1, item2, ecc...)
		
										   - gli items possono essere eterogenei: es: (<a/> , 3)
										   
										   - le query possono contenere duplicati: es: (1,1,1)
										   
										   - le sequenza innestate sono automaticamente appianate: (1,1,(2,3)) -> (1,1,2,3)
										   
		operazioni possibili: unione: rimuove i duplicati es: $x = <a/>	, $y = <b/> , $z = <c/>
															  ($x, $y) union ($y, $z) -> ($x, $y,$z)
															  
		sintassi base = prologo + espressione: - prologo: specifica su quale dominio valutare l'espressione 
		
											   - espressione: espressione da valutare
											   
											   variabili: - let $x := expr
											   
											   funzioni importanti: - doc(docName.xml)	: apre il file
											   						- empty(item*) : dice se è vuoto o no l'elemento
											   						- index-of(item* , item)
											   						- dinstinct-value(item*)
											   						- dinstinct-nodes(node*)
											   						- union(node*, node*)
											   						- contains(string, string)
											   						- date(string)
											   						-deep equal (item1, item2) : ritorna true se tutti gli elementi di item1 sono uguali a quelli di item2 nello stesso ordine
											   	
											   	dichiarare una funzione: declare function ns:foo($x as xs:integer) as element(){
											   									<a>{$x +1}</a>
											   							 }   																							  
		FLWOR expressions: - FOR : for 'variabile' in 'espressione' es: for $x in doc(book.xml)/book
																		return $x/title
							
						   - LET: let 'variabile' := 'espressione'
						   
						   - WHERE: where 'variabile' = 'condizione' , posso legarle con and or ecc...
						   
						   - RETURN: ritorna dei dati xml: posso specificare nuovi tag: es: for $x in doc(book.xml)//book
						   																	where $x/price > 60
						   																	return <expensive_book>
						   																			{$book/title}  <!-- ritorna tag title  -->
						   																		   </expensive_book>
						   																		   
						   - ORDER BY: order by ('variabile' || 'espressione')
						   
						   - IF : if ('condizione') then ('azione')
						   		  else ('azione')
						   		  
						   - JOIN : for $b in doc(book.xml)//book
						   				$p in doc(publisher.xml)//publisher   ------> posso scorrere su 2 documenti diversi e confrontarne i campi
						   			where $b/publisher = $p/name
						   			return ($b/title, $p/address)	
						   			
		inserimento : do_insert 'codice xml' into 'file.xml'
		
		
------------------------- ACTIVE DATABASES -------------------------

Trigger: - definiti da: - nome
						- nome della tabella monitorata
						- metodo di esecuzione (BEFORE azione, AFTER azione)
						- evento monitorato (INSERT, DELETE, UPDATE)
						- granularità ( STATEMENT, ROW)
						- condizione
						- azione da svolgere
						
		   sintassi: create trigger <nome_trigger>
		   			 {before | after}
		   			 {insert | delete | update} on <nome_tabella>
		   			 for each {row | statement}
		   			 when <condizione>
		   			 <codice_SQL>
		   			 
		   			 
		   granularità: - statement: il comando viene considerato ed eseguito una sola volta per ogni istruzione, indipendentemente dal numero di tuple modificate
		   						
		   						2 reference utili: - old table: valore vecchio di tutte le tuple modifcate
		   										
		   										   - new table: valore nuovo di tutte le tuple modificate
		   				
		   				- row: il comando viene eseguito una volta per ogni tupla modificata
		   											 
		   						2 reference utili: - old: valore della tupla prima della modifica
		   										
		   										   - new: valore della tupla dopo la modifica
		   										   
		   	3 proprietà fondamentali: - terminazione: non devono crearsi cicli infiniti
		   							  
		   							  - confluenza: i trigger producono sempre lo stesso stato finale indipendentemente dalla sequenza in cui vengono eseguiti
		   							  
		   							  - determinismo delle osservazioni: devono essere confluenti e produrre la stessa sequenza di messaggi
		   							  
		   							  la proprietà di terminazione viene verificata attraverso l'uso dei grafi: - nodi: uno per ogni trigger
		   							  																			
		   							  																			- archi(i,j): se l'azione del trigger i fa scattare il trigger j
		   							  																			
		   							  se il grafo è aciclico allora è verificata la proprietà di terminazione
		   							  
		   							  se il grafo è ciclico POTEREBBE non terminare (non è detto)