DATABASE 2

------------------------- COMMIT PROTOCOLS -------------------------

ACID distribuito: - Atomicità: proprietà più difficile da ottenere in un sistema distribuito (garantita dai vari protocolli di commit)
				  - Consistenza: se le transazioni preservano la loro integrità sono consistenti, per fare ciò si adotta il 2PL
				  - Isolamento: se tutte le transazioni sono adottano il protocollo "two phase" è garantito
				  - Durabilità: se tutte i branch distribuiti mantengono bene i log è garantita la durabilità
				  
possibili situazioni di errore: - perdita del messaggio
								- problemi ad un nodo (locale)
								- problemi al network
								
protocolli: - Two phase commit: - 2 componenti fondamentali: - transaction manager: coordina i vari componenti in gioco
																					
																					compiti: - prepare: identificare i r. m.
																							 - global commit/abort: prendere decisioni globali sull'esito delle transazioni
																							 - complete: chiudere il protocollo
															
															 - resource manager: nodi local coordinati dal t.m.
															 					
															 					 compiti: - ready: stato che mi identifica agli occhi del t.m (ok se dico si ad una richiesta di prepare)
															 					 		  - local commit/abort: decisione locale sull'esito della transazione
															 					 		  
								funzionamento: - fase 1 : 1 - il t.m scrive sul log "prepare"
														  2 - il t.m manda un messaggio di prepare a tutti gli r.m
														  3 - gli r.m decidono se accettare o no la richiesta di prepare
														  4 - i r.m comunicano la loro decisione al t.m
														  
														  
												- fase 2: 5 - il t.m guarda tutti i messaggi di risposta e se almeno uno è no scrive "global abort" sul log(anche se scade il timeout)
														  	  altrimenti scrive "global commit"
														  6	-  il t.m comunica la decisione a tutti gli r.m
														  7 - gli r.m decidono localmente se accettare o no il commit della transazione
														  8 - gli r.m comunicano con ack al t.m la ricezione del messaggio
														  9 - il t.m scrive "complete" sul log
														  
								problemi: - problemi al t.m : 2 compiti per recuperarlo: - l'ultimo record sul log è "prepare", il fallimento potrebbe aver lasciato dei r.m in stato di blocco 
																						   e si può procedere in 2 modi:
																						   1 - scrivere global abort e portare a termine la fase 2 del protocollo.
																						   2 - ripetere la prima fase
																						   
																						 - l'ultimo record è una global decision, alcuni r.m sono bloccati ripetere la fase 2 del protocollo
																						 
										  - problemi agli r.m : causati da un warm restart: - ultimo record è una local decision: - se commit fare il redo di tutte le azioni dopo
										  																						  - se abort fare l'undo di tutte le azioni
										  													- ultimo record è ready: richiedere l'esito al t.m(remote recovery)
										  													
										  - problemi di network : - perdo messaggi prepare o ready: scade il time out e scrivo global abort
										  						  - perdo messaggi di ack o msg. scade il timeout e ripeto la fase 2 del protocollo
										  						  							   
								ottimizzazioni: - presumed abort protocol: se il t.m riceve un richiesta di remote recovery e non sa ancora in che stato è la transazioe, allora risponde con un global abort
												
												- read-only	optimization: se un r.m vuole solo leggere comunicherà al t.m al posto di "ready" read only e questo r.m  verrà ignorato nella fase 2 del protocollo dal t.m			
												
			- four phase commit: come il two fase cmmit solo che è presente un backup del t.m, ogni volta che il t.m scrive un record sul log lo comunica al backup che a sua volta lo scriverà nel suo log
								 quando si ha un caso di failure nel t.m il backup prenderà il suo posto e diventerà lui il t.m rendendo il failure trasparente.
								 come prima operazione il nuovo t.m creerà un nuovo backup
																	 
			- three phase commit: ogni r.m può essere eletto a t.m: - se come ultimo record ha "ready" allora può ipotizzare che la transazione sia fallita e scrivere global abort
																	- se come ultimo record ha pre- commit può fare un global commit
																										
			- paxos: combina un protocollo con il commit protocol, alcun r.m agiscono da acceptors
										  
			- x-openDTP: espone delle interfacce: - t.m interface: definisce le funzioni del t.m che possono essere chiamate dai client: - tm_init, tm_end: inizia e termina il dialogo con il client
																																		 - t_mopen, tm_term: apre e chiude la sessione con il tm
																																		 - tm_begin: inizia una transazione
																																		 - tm_abort, tm_commit: richiesta di global commit/abort
												  
												  - xa interface: definisce le funzioni dei client remoti	
												  
						  i client sono passivi e il protocollo supporta decisioni euristiche(dopo un failure posso decidere se fare un commit o un abort).
						  usa il protocollo two phase commit con ottimizzazioni		
						  
						  



		
						  
------------------------- DISTRIBUTED DATABASE -------------------------

architetture client server: - client: formula le query e mostra i risultati
							- server: risolve le query e calcola i risultati
							
process nel server: - richieste accodate in una coda di input
					- richieste smistate tra i vari servizi
					- risultato accodato in una coda di output
					- risultato spedito al client appropriato
					
famiglie DBMS: - omogenei: stessa "marca" (oracle, sybase, ecc...)
			   - eterogenei: "marche diverse"
			   
data fragmentation: - proprietà che deve rispettare: - completezza: ogni elemento della tabella T deve essere presente in uno dei suoi frammenti
												     - restorability: la tabella T deve poter essere ricostruita dai suo frammenti
												   
					- tipi di frammentazione: - horizontal fragmentation: - frammento: insieme di tuple
																		  - completezza: disponibilità di tutte le tuple
																		  - restorability: UNIONE di tutte le tuple
											
											  - vertical fragmentation: - frammento: insieme di attributi
																	    - completezza: disponibilità di tutti gli attributi
																	    - restorability: JOIN  sugli attributi
																	  
																	    (PROBLEMA: devo duplicare la chiave primaria su ogni frammento per poter ricostruire)

					- tipi di allocazione: - fully centralized: tutte le tabelle accorpate in un unico db
										   
										   - centralized and distributed (fully replicated): le tabelle risiedono tutte su un unico db ma hanno anche dei doppioni distribuiti su vari altri sistemi
										   
										   - partially distributed, no replication: alcune tabelle sono su un db altre su altri, non ci sono mai dei doppioni
										   
										   - partially centralized and fully distributed: alcune tabelle risiedono su un db centrale mentre nei sotto sistemi risiedono una tabella per OGNI tipo (non posso avere un sotto sistema che non abbia 
										   																																						   un tipo di tabella)
										  
										   - asymmetric allocation: non tutti i sotto sistemi hanno frammenti del sistema centrale
										   
										   - fully distributed, little replication: solo le tuple che hanno un attributo con lo stesso valore sono replicate su più sotto sistemi( es: utente che ha più di un account)
										   
partizionare bene un database: bisogna garantire la TRASPARENZA: 3 livelli: - trasparenza di frammentazione: l'utente vede il db come non frammentato ma unico									
																											 (es: SELECT balance FROM Account WHERE id=1)
																											 
																			- trasparenza di allocazione: l'utente sa che è frammentato ma non ha bisogno di gestire dove sono allocate le risorse, non devo specificare su che macchina
																										  si trovano i frammenti, per lui sono tutti sulla stessa macchina
																										  
																			- trasparenza di linguaggio: l'utente sa che sono frammentate e allocate e lo deve indicare nella query, deve indicare la macchina fisica tramite la "@"s
																			
classificazione applicazioni distribuite SQL: - remote request: permette le sole operazioni di lettura su un unico db
											  - remote transaction: permette l'update su un singolo db
											  - distributed transaction: permette l'update su più db, tutte le query vengono gestite da un singolo db
											  - distributed request: permette l'update e le query vengono gestite da più db

sistemi legacy: basati su vecchi mainframe: - poco documentati
											- obsoleti
											- garantiscono sicurezza 
							
																												





																					
------------------------- PARALLELS AND REPLICATED DB -------------------------		

il parallelismo è garantito dal numero di processori > 1 presenti nel server, possono avere 3 tipi di architetture: - shared nothing: ogni processore ha il suo disco e la sua memoria
																													- shared disk: condividono i vari dischi tra tutti i processori
																													- shared memory: oltre ai dischi condividono anche la memoria centrale

tipi di operazioni: - transactional: operazioni SQL semplici, evase in pochi secondi, il benchmark è misurato in transazioni per secondo
					- data analysis: operazioni complesse, tempo variabile


tipi di parallelismo: - inter-query: tutte le query transazionali vengono svolte su un unico processore
					  - intra-query: le query di data-analysis vengono svolte su più processori contemporaneamente
					  
il costo per transazione aumenta all'aumentare del numero di processori, mentre aumenta il numero di transazioni per secondo

data replication: motivazioni: - ho più probabilità di trovare il dato che cerco se ho più copie( es: se un sistema ha problemi posso prendere il dato da un altro)
 							   - aumenta l'efficienza
 							   
 				  metodi di replicazione: - asymmetric replicaion: se ho un nuovo dato scritto sul sistema è il sistema stesso che si occupa di copiarlo anche sugli altri suoi sistemi copia ( l'update che fa il sistema è considerato una transazione a se)
 				  						  - symmetric replication: quando faccio l'update lo faccio anche su tutti i sistemi copia (tutti gli update sono considerati un unica transazione)
 				  						  
 				  metodi di allineamento: - whole copy: copio tutto il database sui sistemi copia
 				  						  - delta-plus/delta-minus(sono tabelle riempite tramite trigger): aggiungo/rimuovo solo le cose che cambiano
 				  						  
 				  						  
 				  						  


------------------------- DATA WAREHOUSE -------------------------	

data warehouse: descrizione di tutto l'insieme di dati che servono per ricavare una statistica

OLAP: servizi che effettuano analisi suldata warehouse

data mart: sotto-insieme dei data warehouse dove incorporo solo i dati relativi ad una specifica area di business, condividono dati in comune tra i vari data mart

multi-dimensional representation: modello concettuale che descrive l'integrazione tra i vari componenti del data mart.
								  
								  è composto da 3 componenti fondamentali: - fact: componenti fondamentali del data mart (VENDITE ECC..)
								  										   - measures: sono gli attributi del fatto
								  										   - dimension: sono componenti che associati al fatto danno una tabella su cui creare una statistica( es: Prodotto(dimension) - VENDITE(fact), NEGOZIO(dimension) - VENDITE(fact) )
								  
								  è molto utile questo modello perchè è già pronto per essere plamsmato su un db relazionale
								  
								  ogni fatto ha come attributi, oltre alle measures, tutte le chiavi primarie dei dimension a lui collegati
								  
operazioni possibili su data warehouse: - roll up: aggregare tutte le informazioni di un unico valore (es: somma del prodotto vino venduto in un mese)
										- drill down: ricavare il dettaglio di un valore( es: vendita giornaliera del prodotto vino)
										- slice and dice
										- pivot: cambiare angolazione del data cube
										
classificazione OLAP: - ROLAP: basati su db relazionali, possono contenere grandi quantità di dati
					  - MOLAP: ba\sati su db NON relazionali, hanno performance migliori 
					  
					  ottimizzazioni: - bitmap indexes: utili dove ci sono molte operazioni di AND e OR per confrontare predicati
					  				  - join indexes: pre-computano le join tra le tabelle cosi da renderle più efficienti
					  				  - materialized views: pre-computano view utili
					  				  
data mining: processo che permette di ricavare informazioni "nascoste" mettendo insieme più dati tra loro per ricavare una statistica
			
			 si basa sul ragionamento fondamentale body -> head (es: se una persona compra degli sci -> che probabilmente comprerà degli scarponi da sci anche)
			 
			 parametri: - support: probabilità che nella stessa transazione ci sia sia l'head che il body
			 
			 			- confidence: probabilità che ci sia l'head nella transazione t sapendo che c'è il body
			 			



------------------------- PHYSICAL DATA STRUCTURES AND QUERY OPTIMIZATION -------------------------
			 
i DBMS gestiscono i blocchi della memoria secondaria come se fossero un grande spazio unico.
per ogni file storano una tabella ma può anche capitare che un file contenga più tabelle o che una tabella sia splittata su più files

componenti fondamentali: - blocks: componente fisico, la sua grandezza dipende dal file system usato
						 - records: componente logico: la sua grandezza dipende dall'esigenza dell'applicazione
						 
						 se Sr(size record)< Sb(size block) allora posso avere più record all'interno di uno stesso blocco. lo spazio rimanente nel blocco può essere usato(spanned records) oppure no(unspanned recors)
						 
						 
ogni DBMS ha la sua struttura fisica di accesso e i suoi metodi di accesso, i quali sono componenti software che manipolano questa struttura.
la struttura può essere di 3 tipi: - sequential: le tuple vengono immagazzinate in maniera sequenziale sul disco
												 
												 3 tipi diversi: - entry-sequenced: le tuple vengono scritte nell'ordine in cui arrivano; la prima che arriva viene scritta prima
												 									ottima per le operazioni di scrittura e lettura sequenziali
												 									non ottima per la ricerca
												 									
												 				 - array: le tuple possono essere inserite come in u array a second dell'indice; è possibile solo se tutte le tuple hanno la stessa grandezza fissata a priori
												 				 
												 				 - sequentially ordered: le tuple sono ordinate tramite un campo chiamato row key; non si usa quasi più questa tecnica perchè molto poco efficiente quando si ha un inserimento
												 				 
								   - hash based: si basa sul riconoscimento della tupla tramite la coppia chiave valore.
								   				 
								   				 data una struttura di B blocchi, una volta usata la funzione di hash sulla chiave questa restituisce un valore compreso tra 0 e B-1 che è la posizione
								   				  
								   				 2 fasi: - folding: la chiave viene trasformata in un valore intero non negativo
								   				  		 - hashing: la chiave trasformata viene hashata e il valore di ritorno è la posizione della tupla cercata
								   				  		 
								   				  partizionare bene il numero di blocchi: - T: numero di tuple aspettate nella pagina
								   				  										  - F: numero medio di tule presenti in ogni pagina
								   				  										  - B = T/(0.8*F)
								   				  										  
								   				  possono verificarsi collisioni(2 chiavi diverse restituiscono la stessa posizione).
								   				  a questo problema si può ovviare con: - chaining: creo una lista di valori in un unica casella(aggiungo un costo computazionale di O(n) alla ricerca
								   				  										- uso il prossimo blocco in sequenza libero per immagazzinare il valore
								   				  										- uso un file extra chiamato "overflow file" e immagazzino li il dato
								   				  										
								   				  questa struttura è inefficiente sulle ricerche dove non si conosce la chiave o sulle ricerche basate su offset dalla partenza
								   				  	
								
								   - tree based: struttura più usata
								   				
								   				 si avvale di indici( assimilabili all'indice di un libro), possono essere di diversi tipi: - primary index: indice basato sulle chiavi primarie delle tuple
								   				 																							- secondary index: indice basato sugli attributi della tupla
								   				 																							- dense index: per ogni tupla ho un entry nell'index file
								   				 																							- sparse index: ho un entry nell'index file solo ogni tot di tuple
								   				 																							- clustered index: gli indici sono dati dal posizionamento del file nel file system
								   				 																				
								   				 ogni node dell'albero corrisponde a un blocco
								   				 
								   				 2 tipi di albero: - B+ trees: le foglie sono legate tra di loro come una lista, molto efficienti per le interval queries
								   				 				   - B trees: i nodi intermedi hanno 2 puntatori per ogni coppia chiave valore: - uno punta al nodo con la chiave esatta
								   				 				   																				- l'altro punta ad un sotto-albero contenente tutte le chiavi > Ki e < di Ki+1 
								   				 				   																				
								   				 				   	operazioni fondamentali: - SPLIT: se non posso aggiungere una entry in un nodo perchè è pieno allora devo splittare il nodo in 2 e aggiungere il puntatore al nodo padre. cosi mantengo
								   				 				   									  la proprietà che una coppia chiave valore deve puntare sempre a valori di chiave > di K
								   				 				   									  
								   				 				   									  es: nodo padre: 		|| k1 || k6 || || |				inserisco k3					|| k1 || k3 || k6 || |
								   				 				   									  														------------->      
								   				 				   									  	  nodo figlio:		|| k1 || k2 || k4 || k5 |										|| k1 || k2 || || |		|| k3 || k4 || k5 || |
								   				 				   									  	  
								   				 				   							 - MERGE: si ha quando c'e un eliminazione di una chiave e posso unire 2 nodi in uno unico perchè ho tanti posti disponibili quanti sono i valori nel
								   				 				   							 		  blocco da unire
								   				 				   							 		  
								   				 				   							 		  es: nodo padre: 		|| k1 || k3 || k6 || |							 	 elimino k2						|| k1 || k6 ||  || |
								   				 				   									  																			------------->      
								   				 				   									  	  nodo figlio:		|| k1 || k2 || || |		|| k3 || k4 || k5 || |										|| k1 || k3 || k4 || k5 |	
								   				 
								   
nelle strutture sequenziali ed hash based la struttura delle pagine è la stessa ed è la seguente: - block header: contiene le informazioni utili al file system						<------ inizio pagina
																								  
																								  - page header: contiene le informazioni utili al metodo di accesso
																								  
																								  - page dictionary: contiene i puntatori alle varie tuple
																								  
																								  - useful data: contiene le tuple vere e proprie
																								  
																								  - checksum:serve per verificare l'integrità dei dati
																								  
																								  - page trailer: contiene le informazioni utili al metodo di accesso
																								  
																								  - block trailer: contiene le informazioni utili al file system					<------ fine pagina
																								  
																								  
																	
																								  
																			  	 